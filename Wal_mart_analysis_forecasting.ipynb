{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Psyclophe/Data-Scientist/blob/main/Wal_mart_analysis_forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "odggQqNPY5hY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "d7245872-64da-4706-d1c9-347e9f884163"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-21a41c20f120>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpkle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpmdarima\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpmdarima\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpmdarima\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pmdarima'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import datetime as dt\n",
        "import prophet as ppt\n",
        "import pickle as pkle\n",
        "import warnings\n",
        "#import pmdarima as pm\n",
        "#from pmdarima.model_selection import train_test_split\n",
        "#from pmdarima.pipeline import Pipeline\n",
        "#from pmdarima.preprocessing import BoxCoxEndogTransformer\n",
        "warnings.filterwarnings (\"ignore\")\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sección 1.***Obtención de Datos***\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Zt9zsKvTU9qF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKC_NnshZ7_h"
      },
      "outputs": [],
      "source": [
        "#se cargan los datos de entrada proporcionado en el proyecto de las tiendas Wal-mart, \n",
        "#asimismo se hace la conexión de los datos a Github mostrado en la siguiente ruta\n",
        "#de la misma forma se indica a Python muestre los primeros \"20\" registros\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/Psyclophe/Data-Scientist/main/Walmart_Store_sales.csv'\n",
        "df = pd.read_csv (url)\n",
        "\n",
        "df.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sección 2. **Análisis Exploratorio**\n",
        "en esta sección del codigo se procede a realizar el análisis de la información proporcionada"
      ],
      "metadata": {
        "id": "WyNtZnoSUnNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#para identificar los datos nulos se indica a Pthoin que nos muestre los datos y, poder detectar la cantidad de datos nulos\n",
        "\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "TzHDPmGT0ort"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2UFhH8vfble"
      },
      "outputs": [],
      "source": [
        "#con la carga de información y con esta funcion se pide a Python indicar el tipo de dato de cada columna, \n",
        "#para analizar si es necesario hacer cambios en el tipo de dato en el dataframe y poder tener datos homógeneos\n",
        "#se identifico que \"Date\" es un dato que es objeto y se debe convertir a dato fecha\n",
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#en esta función se pide a Python convertir los datos objeto a string\n",
        "#aquí podemos visualizar que el dato que era un objeto \"Date\" se conviritio al formato fecha en donde se visualiza \"datetime64[ns]\"\n",
        "\n",
        "df[\"Date\"]=pd.to_datetime(df[\"Date\"])\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "id": "f8Arzv6O0ZlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K98BydgOkKFi"
      },
      "outputs": [],
      "source": [
        "#con esta funcion se da la instrucción a Python para ver las medidas de tendencia central de las 8 columnas\n",
        "\n",
        "#analizar holiday, temperatura del 75% al max\n",
        "\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-50MQCZDaCK8"
      },
      "outputs": [],
      "source": [
        "#se da la instruccion a Python que se ordene las fechas de menor a mayor en el archivo que se va a analizar\n",
        "#asimismo se indica al programa que ordene por fechas, de la mas antigua hasta la más reciente\n",
        "\n",
        "data_sort=df.sort_values(\"Date\")\n",
        "\n",
        "data_sort"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Year\"]= df['Date'].dt.year\n",
        "df[\"Quarter\"]= df['Date'].dt.Quarter\n",
        "df[\"Month\"]= df['Date'].dt.month\n",
        "df[\"Week\"]= df['Date'].dt.week\n",
        "df[\"Day\"]= df['Date'].dt.day\n",
        "df\n",
        "\n",
        "df['Year']=df['Date'].dt.year\n",
        "df['Month']=df['Date'].dt.month\n",
        "df['Day']=df['Date'].dt.day\n",
        "\n",
        "\n",
        "#df[\"Week\"]= pd.DatetimeIndex(df['Date']).week\n",
        "#df['Month'] = pd.DatetimeIndex(df['Date']).month\n",
        "#df['Year'] = pd.DatetimeIndex(df['Date']).year\n",
        "#df"
      ],
      "metadata": {
        "id": "ZSP4aUFKf3w_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVngjONhooXn"
      },
      "outputs": [],
      "source": [
        "#con la funcion \"groupby\" se indica a Python agrupar y sumar, por tienda y por semana, al ejecutar la función Python\n",
        "#agrega e indexa la columna \"0\" a la columna \"1\" como identificador\n",
        "#Las ventas estan expresadas en miles (´000)\n",
        "\n",
        "group=df.groupby(\"Store\").sum(\"Weekly_Sales\")\n",
        "group.reset_index(level=0, inplace=True)\n",
        "group[\"Weekly_Sales\"]=(group[\"Weekly_Sales\"]/1000).round(2)\n",
        "group[\"Fuel_Price\"]=(group[\"Fuel_Price\"]).round(2)\n",
        "group[\"CPI\"]=(group[\"CPI\"]).round(2)\n",
        "group[\"Unemployment\"]=(group[\"Unemployment\"]).round(2)\n",
        "\n",
        "group"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#se solicita a Python ordenar por tienda y por volumen de ventas\n",
        "\n",
        "sort_WeeklySales=group.sort_values('Weekly_Sales', ascending=False)\n",
        "\n",
        "sort_WeeklySales"
      ],
      "metadata": {
        "id": "megkRNSqYZaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script le indicamos a Python que solo nos indique el Top_five de las ventas por tienda\n",
        "\n",
        "Top_five=sort_WeeklySales[['Weekly_Sales', 'Store']][0:5:].reset_index(drop=True)\n",
        "Top_five"
      ],
      "metadata": {
        "id": "gtSAJHai0DlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#es este script se solicita a Python calcular la Desviacioón Estandar por tienda, ordenanda de mayor a menor\n",
        "\n",
        "Store_devstd = df.groupby('Store')['Weekly_Sales'].std()\n",
        "Store_devstd = pd.DataFrame(Store_devstd)\n",
        "Store_devstd=Store_devstd.sort_values('Weekly_Sales', ascending=False)\n",
        "\n",
        "Store_devstd"
      ],
      "metadata": {
        "id": "sl0X1ax8GmgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# con este script se determina el Coeficiente de Desviación Medio por tienda\n",
        "#se determinó dividiendo la DesvStd por tienda entre la media de las tiendas\n",
        "\n",
        "coeficiente_DM = pd.DataFrame(df.groupby('Store')['Weekly_Sales'].std() / df.groupby('Store')['Weekly_Sales'].mean()*100)\n",
        "coeficiente_DM\n"
      ],
      "metadata": {
        "id": "NaGBlE2VX3Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se pide a Python identificar los días festivos\n",
        "\n",
        "df_Holiday=df[df[\"Holiday_Flag\"]==1]\n",
        "\n",
        "df_Holiday"
      ],
      "metadata": {
        "id": "RQ-27JzWEdaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con esta instrucción se definen los Días festivos que encontro Pyton en el dataframe\n",
        "\n",
        "Super_Bowl =['2010-12-02', '2011-11-02', '2012-10-02']\n",
        "Labor_Day =  ['2010-10-09', '2011-09-09', '2012-07-09']\n",
        "Thanksgivig_Day =  ['2010-11-26', '2011-11-25', '2012-11-23']\n",
        "Xmas = ['2010-12-31', '2011-12-30', '2012-12-28']"
      ],
      "metadata": {
        "id": "mSNpf7TyIZVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.loc[df.Date.isin(Super_Bowl)].Date.unique()\n",
        "#df.loc[df.Date.isin(Labor_Day)].Date.unique()\n",
        "#df.loc[df.Date.isin(Thanksgivig_Day)].Date.unique()\n",
        "#df.loc[df.Date.isin(Xmas)].Date.unique()"
      ],
      "metadata": {
        "id": "w2d6RqtvEGKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con esta instrucción se pide a Python determinar la media de ventas de los Días_Festivos\n",
        "\n",
        "Sales_Super_Bowl= (pd.DataFrame(df.loc[df.Date.isin(Super_Bowl)]))['Weekly_Sales'].mean()\n",
        "Sales_Labor_Day = (pd.DataFrame(df.loc[df.Date.isin(Labor_Day)]))['Weekly_Sales'].mean()\n",
        "Sales_Thanksgivig_Day = (pd.DataFrame(df.loc[df.Date.isin(Thanksgivig_Day)]))['Weekly_Sales'].mean()\n",
        "Sales_Xmas = (pd.DataFrame(df.loc[df.Date.isin(Xmas)]))['Weekly_Sales'].mean()\n",
        "\n",
        "{Sales_Super_Bowl, Sales_Labor_Day, Sales_Thanksgivig_Day, Sales_Xmas}"
      ],
      "metadata": {
        "id": "GtIItzEHN_oH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con esta instrucción se pide a Python determinar la media de ventas de los Dias_No_Festivos\n",
        "\n",
        "Sales_not_Holiday = df[df['Holiday_Flag'] == 0 ]['Weekly_Sales'].mean()\n",
        "\n",
        "{Sales_not_Holiday}"
      ],
      "metadata": {
        "id": "rUSlykMtSRAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con esta instrucción se pide a Python determinar el promedio de ventas \n",
        "\n",
        "Average_sales = {'Sales_Super_Bowl' : Sales_Super_Bowl,\n",
        "                 'Sales_Labor_Day': Sales_Labor_Day,\n",
        "                 'Sales_Thanksgiving_Day':Sales_Thanksgivig_Day,\n",
        "                 'Sales_Xmas': Sales_Xmas,\n",
        "                 'Sales_not_Holiday': Sales_not_Holiday}\n",
        "\n",
        "Average_sales "
      ],
      "metadata": {
        "id": "oVXZJfSBI4ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se muestra en crecimiento tercer trimestre 2012 por tienda\n",
        "\n",
        "third_quarter= df[(df['Date'] >= '2012-07-01') & (df['Date'] <= '2012-09-30')].groupby('Store')['Weekly_Sales'].sum().sort_values()\n",
        "plt.figure(figsize=(15,7))\n",
        "third_quarter.plot(kind='bar',legend=True)\n",
        "plt.ticklabel_format( style='plain', axis='y')\n",
        "plt.legend([\"3rd-Quarter' 2012\"]);\n"
      ],
      "metadata": {
        "id": "jAfPHkBkcE6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sección 3. **Modelado**\n",
        "en esta sección del codigo se procede a realizar el modelado y forecasting de la información proporcionada"
      ],
      "metadata": {
        "id": "XquZb_i_bqF5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jhk8ddxQBHn3"
      },
      "outputs": [],
      "source": [
        "fig = px.box(data_sort, y = \"Weekly_Sales\", x = \"Store\",  color = \"Store\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtuoNBdeBdsR"
      },
      "outputs": [],
      "source": [
        "sns.set_theme(style='darkgrid')\n",
        "plt.figure(figsize=(30,12))\n",
        "sns.lineplot(data=store, x='Date', y='Weekly_Sales', hue='Store', palette='tab10')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWkj8XgzJwa9"
      },
      "outputs": [],
      "source": [
        "f, ax=plt.subplots(figsize=(12,8))\n",
        "sns.barplot(x='Store', y='Weekly_Sales', data=sort5, order=sort5.sort_values('Weekly_Sales').Store)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfmXdce8WxVK"
      },
      "outputs": [],
      "source": [
        "df_Year=df.groupby('Year')['Weekly_Sales'].sum()\n",
        "df_Year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIYCTg58fuH_"
      },
      "outputs": [],
      "source": [
        "df[(df['Date'] - pd.to_datetime('2010-02-12')).abs().min()==(df['Date'] - pd.to_datetime('2010-02-12')).abs()]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_theme(style='darkgrid')\n",
        "plt.figure(figsize(20,8))\n",
        "sns.lineplot(data=store1, x='Date', y='Weekly_Sales', hue='Store', palette='tab10')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bk8Yd51g2ctq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyMwqfCVDS/apgFJWzXTBnng",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}