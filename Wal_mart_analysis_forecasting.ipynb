{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Psyclophe/Data-Scientist/blob/main/Wal_mart_analysis_forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "odggQqNPY5hY",
        "outputId": "7e4736c9-e0db-4f36-e0d7-07d2d77ab25c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pmdarima\n",
            "  Downloading pmdarima-2.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (0.29.32)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.7.3)\n",
            "Collecting statsmodels>=0.13.2\n",
            "  Downloading statsmodels-0.13.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 28.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (57.4.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.0.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.24.3)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->pmdarima) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->pmdarima) (2022.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.19->pmdarima) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->pmdarima) (3.1.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.13.2->pmdarima) (0.5.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.13.2->pmdarima) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=21.3->statsmodels>=0.13.2->pmdarima) (3.0.9)\n",
            "Installing collected packages: statsmodels, pmdarima\n",
            "  Attempting uninstall: statsmodels\n",
            "    Found existing installation: statsmodels 0.12.2\n",
            "    Uninstalling statsmodels-0.12.2:\n",
            "      Successfully uninstalled statsmodels-0.12.2\n",
            "Successfully installed pmdarima-2.0.1 statsmodels-0.13.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "statsmodels"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bae0331c7995>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install pmdarima'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpmdarima\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpmdarima\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marima\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauto_arima\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpmdarima\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pmdarima/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# Stuff we want at top-level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marima\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauto_arima\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mARIMA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoARIMA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStepwiseContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecompose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0macf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautocorr_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_acf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_pacf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mtsdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pmdarima/arima/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapprox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marima\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pmdarima/arima/arima.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgaussian_kde\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_validation\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/statsmodels/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miolib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrobust\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m from .discrete.count_model import (\n\u001b[1;32m     75\u001b[0m     \u001b[0mZeroInflatedGeneralizedPoisson\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/statsmodels/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_version\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__version_tuple__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdebug_warnings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdebug_warnings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name '__version__' from 'statsmodels._version' (/usr/local/lib/python3.7/dist-packages/statsmodels/_version.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import datetime\n",
        "from pandas.core.indexes.datetimes import date\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import statsmodels as sm\n",
        "import sklearn as sl\n",
        "\n",
        "!pip install pmdarima\n",
        "\n",
        "import pmdarima as pm\n",
        "from pmdarima.arima import auto_arima\n",
        "from pmdarima.model_selection import train_test_split\n",
        "from pmdarima.pipeline import Pipeline\n",
        "from pmdarima.preprocessing import BoxCoxEndogTransformer\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import datetime as dt\n",
        "\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "import statsmodels.stats.multicomp as multi\n",
        "\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "import statsmodels.stats.multicomp as mutti\n",
        "\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "from statsmodels.compat.scipy import _next_regular\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings (\"ignore\")\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sección 1.***Obtención de Datos***\n",
        "es este apartado se sube la información del dataFrame en github\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Zt9zsKvTU9qF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKC_NnshZ7_h"
      },
      "outputs": [],
      "source": [
        "#se cargan los datos de entrada proporcionado en el proyecto de las tiendas Wal-mart, asimismo se hace la conexión de los datos a Github mostrado en la siguiente ruta\n",
        "#de la misma forma se indica a Python muestre los primeros \"15\" registros\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/Psyclophe/Data-Scientist/main/Walmart_Store_sales.csv'\n",
        "df = pd.read_csv (url)\n",
        "print('Shape of data',df.shape)\n",
        "df.head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sección 2. **Análisis Exploratorio**\n",
        "en esta sección se procede a realizar el análisis de la información proporcionada con Python"
      ],
      "metadata": {
        "id": "WyNtZnoSUnNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#para identificar el tipo de datos se pide a Python que nos muestre los diferentes tipos datos y, poder detectar la cantidad de datos nulos\n",
        "\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "TzHDPmGT0ort"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2UFhH8vfble"
      },
      "outputs": [],
      "source": [
        "#con la carga de informacion y con esta funcion se pide a Python indicar el tipo de dato de cada columna, para analizar si es necesario hacer cambios en el tipo de \n",
        "#dato en el dataframe y poder tener datos homogeneos se identifico que \"Date\" es un dato que es objeto y se debe convertir a dato fecha\n",
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "QWGquBuQPb4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#en esta funcion se pide a Python convertir los datos objeto a string\n",
        "#aquí podemos visualizar que el dato que era un objeto \"Date\" se conviritio al formato fecha en donde se visualiza \"datetime64[ns]\"\n",
        "\n",
        "df[\"Date\"]=pd.to_datetime(df[\"Date\"])\n",
        "df.info()"
      ],
      "metadata": {
        "id": "f8Arzv6O0ZlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se pide a Pyhon poner en formato a las cifras de la informacion de dataset\n",
        "\n",
        "pd.options.display.float_format='{:,.2f}'.format"
      ],
      "metadata": {
        "id": "96wb7KgnS6Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K98BydgOkKFi"
      },
      "outputs": [],
      "source": [
        "#con esta funcion se da la instrucción a Python para ver las medidas de tendencia central de las 8 columnas\n",
        "\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-50MQCZDaCK8"
      },
      "outputs": [],
      "source": [
        "#se da la instruccion a Python que se ordene las fechas de menor a mayor en el archivo que se va a analizar asimismo se indica al programa que ordene por fechas, \n",
        "#de la mas antigua hasta la mas reciente\n",
        "\n",
        "data_sort=df.sort_values(\"Date\")\n",
        "data_sort"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se pide a Python separar el dato \"Date\" en year, quarter, month, week & day,\n",
        "\n",
        "df[\"Year\"]= df['Date'].dt.year\n",
        "df[\"Quarter\"]= df['Date'].dt.quarter\n",
        "df[\"Month\"]= df['Date'].dt.month\n",
        "df[\"Week\"]= df['Date'].dt.week\n",
        "df[\"Day\"]= df['Date'].dt.day\n",
        "df"
      ],
      "metadata": {
        "id": "GcKqVBpwLILa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVngjONhooXn"
      },
      "outputs": [],
      "source": [
        "#con la funcion \"groupby\" se indica a Python agrupar y sumar, por tienda y por semana, al ejecutar el script Python agrega e indexa la columna \"0\" a la columna \"1\" \n",
        "#como identificador\n",
        "\n",
        "group=df.groupby(\"Store\").sum(\"Weekly_Sales\")\n",
        "group.reset_index(level=0, inplace=True)\n",
        "group[\"Weekly_Sales\"]=(group[\"Weekly_Sales\"])\n",
        "group"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se pide a Python agrupar por año al dataset\n",
        "\n",
        "group=df.groupby(\"Year\").sum(\"Weekly_Sales\")\n",
        "group.reset_index(level=0, inplace=True)\n",
        "group[\"Weekly_Sales\"]=(group[\"Weekly_Sales\"])\n",
        "group"
      ],
      "metadata": {
        "id": "Is5jyWjTh06v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group=df.groupby(\"Quarter\").sum(\"Weekly_Sales\")\n",
        "group.reset_index(level=0, inplace=True)\n",
        "group[\"Weekly_Sales\"]=(group[\"Weekly_Sales\"])\n",
        "group"
      ],
      "metadata": {
        "id": "54f2mbgDO-gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.set_index('Quarter')"
      ],
      "metadata": {
        "id": "ZciZl4mAklom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(20,8))\n",
        "sns.lineplot(data=df, x='Quarter', y='Weekly_Sales', hue='Year', palette='tab10')\n",
        "sns.set_style('whitegrid')\n",
        "sns.despine(left=True, offset=20, trim=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ThCT7FayQ177"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cufflinks as cf\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "cf.set_config_file(sharing='public', theme='ggplot', offline=True)\n",
        "cf.getThemes()"
      ],
      "metadata": {
        "id": "Fg2IEqRwrjAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_pivot = df.pivot(index='Year', columns = 'Quarter',\n",
        "#              values = 'Weekly_Sales')"
      ],
      "metadata": {
        "id": "w_8qCkSdGqNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.iplot()"
      ],
      "metadata": {
        "id": "yCCdEds5FEF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "YqRMyXXAmyS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dfd = dfd.groupby(pd.PeriodIndex(dfd.columns, freq='Quarter'), axis =0).sum()\n",
        "#print(dfd.head(5))"
      ],
      "metadata": {
        "id": "9rxku66vfB9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sum_monthly=dfd.sum(axis=1)\n",
        "#print(sum_monthly)"
      ],
      "metadata": {
        "id": "i3GF-TdfpAZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(dfd.groupby(['Weekly_Sales', 'Quarter']).sum())"
      ],
      "metadata": {
        "id": "gV7sR9i1Dsmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df=pd('Quarter')\n",
        "#df_Quarter=df[\"Date\"].dt.quarter\n",
        "#Period=df[period.third_quarter('Date')]\n",
        "#df = df.index.quarter\n",
        "#group=df.groupby(df.index.quarter).head(1).reset_index()\n",
        "#group"
      ],
      "metadata": {
        "id": "6-OnSUXzvnH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#se solicita a Python ordenar por tienda y por volumen de ventas, del valor mayor al menor\n",
        "\n",
        "sort_WeeklySales=group.sort_values('Weekly_Sales', ascending=False)\n",
        "sort_WeeklySales"
      ],
      "metadata": {
        "id": "megkRNSqYZaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script le indicamos a Python que solo nos indique el Top_five de las ventas por tienda\n",
        "\n",
        "Top_five=sort_WeeklySales[['Weekly_Sales', 'Store']][0:5:].reset_index(drop=True)\n",
        "Top_five"
      ],
      "metadata": {
        "id": "gtSAJHai0DlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sort_Quarter=Quarter[['Year', 'Quarter']][0:5:].reset_index(drop=True)\n",
        "#Sort_Quarter\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BAO3LHJvbIqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#es este script se solicita a Python calcular la Desviacion Estandar por tienda, ordenanda de mayor a menor\n",
        "\n",
        "Store_devstd = df.groupby('Store')['Weekly_Sales'].std()\n",
        "Store_devstd = pd.DataFrame(Store_devstd)\n",
        "Store_devstd=Store_devstd.sort_values('Weekly_Sales', ascending=False)\n",
        "Store_devstd"
      ],
      "metadata": {
        "id": "sl0X1ax8GmgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script Python hace el calculo de la tienda con más desviacion estandar\n",
        "\n",
        "top_std = pd.DataFrame(df.groupby('Store')['Weekly_Sales'].std().sort_values(ascending=False))\n",
        "top_std.head(1).index[0] , top_std.head(1).Weekly_Sales[top_std.head(1).index[0]] "
      ],
      "metadata": {
        "id": "d_ttf8iQlVnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# con este script se determina el -Coeficiente de Desviación Medio- por tienda el\n",
        "#se determino dividiendo la DesvStd por tienda entre la media de las tiendas, como sigue coeficiente_DM = Desviación Estandar / media aritmetica * 100\n",
        "\n",
        "coeficiente_DM = pd.DataFrame(df.groupby('Store')['Weekly_Sales'].std() / df.groupby('Store')['Weekly_Sales'].mean()*100)\n",
        "coeficiente_DM"
      ],
      "metadata": {
        "id": "NaGBlE2VX3Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se pide a Python identificar los días festivos\n",
        "\n",
        "df_Holiday=df[df[\"Holiday_Flag\"]==1]\n",
        "df_Holiday"
      ],
      "metadata": {
        "id": "RQ-27JzWEdaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con esta instruccion se definen los Días festivos que encontro Pyton en el dataframe\n",
        "\n",
        "Super_Bowl =['2010-12-02', '2011-11-02', '2012-10-02']\n",
        "Labor_Day =  ['2010-10-09', '2011-09-09', '2012-07-09']\n",
        "Thanksgivig_Day =  ['2010-11-26', '2011-11-25', '2012-11-23']\n",
        "Xmas = ['2010-12-31', '2011-12-30', '2012-12-28']"
      ],
      "metadata": {
        "id": "mSNpf7TyIZVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se pide a Python sumar los dias festivos\n",
        "\n",
        "add_days = Super_Bowl + Labor_Day + Thanksgivig_Day + Xmas\n",
        "add_days\n",
        "df[\"Holiday_Flag\"] = np.where(df[\"Holiday_Flag\"] == 1, df[\"Holiday_Flag\"], df[\"Holiday_Flag\"].isin(add_days))\n",
        "df['Holiday_Flag'].value_counts()"
      ],
      "metadata": {
        "id": "lo-psDwjahEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df.Date.isin(Super_Bowl)].Date.unique()"
      ],
      "metadata": {
        "id": "w2d6RqtvEGKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df.Date.isin(Labor_Day)].Date.unique()"
      ],
      "metadata": {
        "id": "Tch_nwCbIIm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df.Date.isin(Thanksgivig_Day)].Date.unique()"
      ],
      "metadata": {
        "id": "B4s1tsdiIB7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df.Date.isin(Xmas)].Date.unique()"
      ],
      "metadata": {
        "id": "QAS3tLsMIQjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con esta instruccion se pide a Python determinar la media de ventas de los Dias_Festivos\n",
        "\n",
        "Sales_Super_Bowl= (pd.DataFrame(df.loc[df.Date.isin(Super_Bowl)]))['Weekly_Sales'].mean()\n",
        "Sales_Labor_Day = (pd.DataFrame(df.loc[df.Date.isin(Labor_Day)]))['Weekly_Sales'].mean()\n",
        "Sales_Thanksgivig_Day = (pd.DataFrame(df.loc[df.Date.isin(Thanksgivig_Day)]))['Weekly_Sales'].mean()\n",
        "Sales_Xmas = (pd.DataFrame(df.loc[df.Date.isin(Xmas)]))['Weekly_Sales'].mean()\n",
        "{Sales_Super_Bowl, Sales_Labor_Day, Sales_Thanksgivig_Day, Sales_Xmas}"
      ],
      "metadata": {
        "id": "GtIItzEHN_oH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con esta instruccion se pide a Python determinar la media de ventas de los Dias_No_Festivos\n",
        "\n",
        "Sales_not_Holiday = df[df['Holiday_Flag'] == 0 ]['Weekly_Sales'].mean()\n",
        "{Sales_not_Holiday}"
      ],
      "metadata": {
        "id": "rUSlykMtSRAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con esta instruccion se pide a Python determinar el promedio de ventas \n",
        "\n",
        "Average_sales = {'Sales_Super_Bowl' : Sales_Super_Bowl,\n",
        "                 'Sales_Labor_Day': Sales_Labor_Day,\n",
        "                 'Sales_Thanksgiving_Day':Sales_Thanksgivig_Day,\n",
        "                 'Sales_Xmas': Sales_Xmas,\n",
        "                 'Sales_not_Holiday': Sales_not_Holiday}\n",
        "Average_sales "
      ],
      "metadata": {
        "id": "oVXZJfSBI4ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Sales_Quarter=df.groupby('Quarter')['Weekly_Sales'].sum()\n",
        "Sales_Quarter"
      ],
      "metadata": {
        "id": "cOU4f_HuvLcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('Quarter').sum()"
      ],
      "metadata": {
        "id": "sVs9AMBZxTu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "KUbD9NcotwHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "sns.lineplot(data=df, x='Quarter', y='Weekly_Sales', hue='Year', palette='tab10')\n",
        "sns.set_style('whitegrid')\n",
        "sns.despine(left=True, offset=20, trim=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Emr0ZIOoFVpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.groupby.groupby import DataFrame\n",
        "\n",
        "#con este script se pide a Python realizar la suma y acumulacion por Quarter\n",
        "\n",
        "pd=DataFrame({'Year', 'Quarter'})\n",
        "print(df.groupby(['Year', 'Quarter']).sum().groupby(level=[0]).cumsum())"
      ],
      "metadata": {
        "id": "UHLAUV5vx7z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se pide a Python sumar el total de ventas por Quarter\n",
        "Sales_Year=df.groupby('Year')['Weekly_Sales'].sum()\n",
        "Sales_Year"
      ],
      "metadata": {
        "id": "165wxfb9vVZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(20,8))\n",
        "sns.lineplot(data=df, x='Year', y='Weekly_Sales', hue='Quarter', palette='tab10')\n",
        "sns.set_style('whitegrid')\n",
        "sns.despine(left=True, offset=20, trim=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K-5h_CYFxoer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df = df.set_index['Date']\n",
        "#group=df.groupby(df.index.quarter).head(1).reset_index()\n",
        "#print('Shape of data',df.shape)\n",
        "#group"
      ],
      "metadata": {
        "id": "lanXcHPawaER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se muestra en crecimiento tercer trimestre 2012 por tienda\n",
        "\n",
        "#third_quarter= df[(df['Date'] >= '2012-07-01') & (df['Date'] <= '2012-09-30')].groupby('Store')['Weekly_Sales'].sum().sort_values()\n",
        "#plt.figure(figsize=(15,7))\n",
        "#third_quarter.plot(kind='bar',legend=True)\n",
        "#plt.ticklabel_format( style='plain', axis='y')\n",
        "#plt.legend([\"3-Quarter' 2012\"]);\n"
      ],
      "metadata": {
        "id": "jAfPHkBkcE6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se pide a Python graficar las Ventas mensuales por cada año \n",
        "\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.scatter(df[df.Year==2010][\"Month\"],df[df.Year==2010][\"Weekly_Sales\"])\n",
        "plt.xlabel(\"Months\")\n",
        "plt.ylabel(\"Weekly Sales\")\n",
        "plt.title(\"Monthly view of sales in 2010\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.scatter(df[df.Year==2011][\"Month\"],df[df.Year==2011][\"Weekly_Sales\"])\n",
        "plt.xlabel(\"Months\")\n",
        "plt.ylabel(\"Weekly Sales\")\n",
        "plt.title(\"Monthly view of sales in 2011\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.scatter(df[df.Year==2012][\"Month\"],df[df.Year==2012][\"Weekly_Sales\"])\n",
        "plt.xlabel(\"Months\")\n",
        "plt.ylabel(\"Weekly Sales\")\n",
        "plt.title(\"Monthly view of sales in 2012\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MFNT-chLshTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con esta instrucción se pide a Python graficar las ventas de los tres años de manera mensual\n",
        "\n",
        "plt.figure(figsize=(20,8))\n",
        "sns.lineplot(data=df, x='Month', y='Weekly_Sales', hue='Year', palette='tab10')\n",
        "sns.set_style('whitegrid')\n",
        "sns.despine(left=True, offset=20, trim=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C0_RiJNuwief"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Series de tiempo**"
      ],
      "metadata": {
        "id": "xtdk68Gj6wOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df.index, df['Weekly_Sales'])\n",
        "\n",
        "plt.xlabel('Year', fontsize=14 )\n",
        "plt.ylabel('Quarter', fontsize=14)\n",
        "plt.title('Series de tiempo', fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zboZQcYcG4RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "x=['Holiday_Flag']\n",
        "y=['Weekly_Sales']\n",
        "stats.kruskal(x,y)"
      ],
      "metadata": {
        "id": "QIs0f3ZxP0W0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=df[df['Holiday_Flag'] == 0]['Weekly_Sales']\n",
        "y=df[df['Holiday_Flag'] == 1]['Weekly_Sales']\n",
        "stats.kruskal(x,y)"
      ],
      "metadata": {
        "id": "CYTU3exWP8mE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sección 3. **Quitar Valores de Rango**\n",
        "en esta sección del codigo se analiza la información para quitar los valores fuera de rango\n"
      ],
      "metadata": {
        "id": "jqh0mU0kv5fN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se grafican y validan los valores atipicos\n",
        "\n",
        "fig, axis = plt.subplots(4,figsize=(16,16))\n",
        "X = df[['Temperature','Fuel_Price','CPI','Unemployment']]\n",
        "for i,column in enumerate(X):\n",
        "    sns.boxplot(df[column],ax=axis[i])"
      ],
      "metadata": {
        "id": "rTyptJonwBIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(data=df,x='Temperature', y='Weekly_Sales', hue='Year', style='Year')\n",
        "#sns.scatterplot(data=df,x='Temperature', y='Weekly_Sales', hue='Year')\n",
        "plt.axvline(x=10,color='b')"
      ],
      "metadata": {
        "id": "5zX7lA0HZmg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#sns.scatterplot(data=df,x='Holiday_Flag', y='Temperature')\n"
      ],
      "metadata": {
        "id": "o7u6GhF9U5mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(data=df,x='Unemployment', y='Weekly_Sales', hue='Year', style='Year')\n",
        "plt.axvline(x=4.5,color='b')"
      ],
      "metadata": {
        "id": "1xtzeTPUwJYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script pedimos aPython eliminar los valores atipicos en una nueva función\n",
        "\n",
        "df_clean = df[(df['Unemployment']<10) & (df['Unemployment']>4.5) & (df['Temperature']>10)]\n"
      ],
      "metadata": {
        "id": "UDqDTjjgaq-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lim_inf = Q1 - 1.5(whis) IQR (scipy.stats.iqr)\n",
        "#iqr = Q3 - Q1\n",
        "#lim_sup = Q3 + 1.5(whis) IQR"
      ],
      "metadata": {
        "id": "evCLp-chd6C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificamos ya no tener valores atipicos\n",
        "\n",
        "fig, axis = plt.subplots(4,figsize=(16,16))\n",
        "X = df_clean[['Temperature','Fuel_Price','CPI','Unemployment']]\n",
        "for i,column in enumerate(X):\n",
        "    sns.boxplot(df_clean[column],ax=axis[i])\n"
      ],
      "metadata": {
        "id": "3_IZNvZCaw7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este grafico de calor podemos ver las correlaciones de las diferentes columnas\n",
        "\n",
        "plt.figure(figsize = (12,12))\n",
        "sns.heatmap(df_clean.corr().abs())    \n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YDRVQJsja9tD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con esta instrucción se pide a Python graficar las ventas de los tres años por Quarter\n",
        "\n",
        "plt.figure(figsize=(20,8))\n",
        "sns.lineplot(data=df, x='Month', y='Weekly_Sales', hue='Quarter', palette='tab10')\n",
        "sns.set_style('whitegrid')\n",
        "sns.despine(left=True, offset=20, trim=True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2qaLFhGNzEHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sección 4. **Modelos y Pronostico**\n",
        "\n",
        "en esta sección del codigo se procede a realizar el modelado de la información"
      ],
      "metadata": {
        "id": "mFf_DFQk6P11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sns.distplot=sns.distplot('Quarter')"
      ],
      "metadata": {
        "id": "59FxkQr9jf4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import prophet as ppt"
      ],
      "metadata": {
        "id": "kRHj3JGBJ9H2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se solicita a Python calcular el analsis de variaza entre 'Holiday_ Flag' vs 'Weekly_Sales', el modelo indica que la variacion\n",
        "#es pequeña indicando al modelo que los Holiday no afecta las ventas semanales de manera significativa\n",
        "\n",
        "model = smf.ols ('Holiday_Flag ~ Weekly_Sales', data = df).fit()\n",
        "aov_table = anova_lm(model, type=2)\n",
        "\n",
        "#anova_result = sm.stats.anova_lm(model, type=2)\n",
        "print(aov_table)"
      ],
      "metadata": {
        "id": "S5P_FibdKjcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "from pmdarima import auto_arima"
      ],
      "metadata": {
        "id": "gSJrsEa5agFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_arima=df\n",
        "df_arima=df_arima.set_index('Date').reset.index()"
      ],
      "metadata": {
        "id": "i0M9_sIl6HOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.figure(figsize=(20,9))\n",
        "#df_arima['Weekly_Sales'].plot()\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "2U-xeXV_6mEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_arimamonth = df_arima.resample('M').mean()"
      ],
      "metadata": {
        "id": "igL9dh2p7AAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.figure(figsize=(20,8))\n",
        "#df_arimamonth['Weekly_Sales'].plot()\n",
        "#plt.title('Average Sales - Weekly')\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "KBvKckbH7PJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_data = df_arimamonth[:int(0.7*(len(df_arimamonth)))] \n",
        "#test_data = df_arimamonth[int(0.7*(len(df_arimamonth))):]\n",
        "\n",
        "#print('Train:', train_data.shape)\n",
        "#print('Test:', test_data.shape)"
      ],
      "metadata": {
        "id": "k8HY0hu97gAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['Weekly_Sales'].plot(figsize=(20,8), title= 'Weekly_Sales', fontsize=14)\n",
        "test_data['Weekly_Sales'].plot(figsize=(20,8), title= 'Weekly_Sales', fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iOhwuHro7kby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pmdarima.arima import ADFTest\n",
        "adf_test = ADFTest(alpha = 0.05)\n",
        "adf_test.should_diff (df_arimamonth['Weekly_Sales'])"
      ],
      "metadata": {
        "id": "TINXW7s672qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_auto_arima = auto_arima(train_data['Weekly_Sales'], trace=True,start_p=0, start_q=0, start_P=0, start_Q=0,\n",
        "                  max_p=20, max_q=20, max_P=20, max_Q=20, seasonal=True,maxiter=200,\n",
        "                  information_criterion='aic',stepwise=False, suppress_warnings=True, D=0, max_D=0,\n",
        "                  error_action='ignore',approximation = False)\n",
        "model_auto_arima.fit(train_data['Weekly_Sales'])"
      ],
      "metadata": {
        "id": "jMkQg0xq8K35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_auto_arima.summary()"
      ],
      "metadata": {
        "id": "2Ei9O6rN8TZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model_auto_arima.predict(n_periods=len(test_data['Weekly_Sales']))\n",
        "y_pred = pd.DataFrame(y_pred,index = test_data['Weekly_Sales'].index,columns=['Prediction'])\n",
        "plt.figure(figsize=(20,6))\n",
        "plt.title('Prediction of Weekly Sales Using Auto-ARIMA', fontsize=20)\n",
        "plt.plot(train_data['Weekly_Sales'], label='Train')\n",
        "plt.plot(test_data['Weekly_Sales'], label='Test')\n",
        "plt.plot(y_pred, label='Prediction of ARIMA')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('Date', fontsize=14)\n",
        "plt.ylabel('Weekly Sales', fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RIv8J8NH8Yda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este escript se elige el tipo de modelo\n",
        "\n",
        "#import statsmodels as sm\n",
        "#from statsmodels.tsa.arima_model import ARIMA\n",
        "#from statsmodels.tsa.stattools import adfuller\n",
        "#def test_stationarity(timeseries):\n",
        "\n",
        "#estadisticas en la determinación de la media móvil y la desviación estandar\n",
        "#  rolmean = pd.rolling_mean(timeseries, window=12)\n",
        "#  rolstd = pd.rolling_std(timeseries, window=12)\n",
        "\n",
        "#graficar las estadisticas\n",
        "#  orig = plt.plot(timeseries, color=\"blue\", label=\"Original\")\n",
        "#  mean = plt.plot(rolmean, color=\"red\", label=\"Media Movil\")\n",
        "#  std = plt.plot(rolstd, color=\"black\", label=\"Desviacon Estandar\")\n",
        "#  plt.legend(loc=\"best\")\n",
        "#  plt.title(\"Media Movil y Desviacion Estandar\")\n",
        "#  plt.show(block=False)\n",
        "\n",
        "\n",
        "#calculo de la media movil\n",
        "#moving_avg = pd.rolling_mean(datos[\"Weekly_Sales\"], 12)\n",
        "#datos[\"Weekly_Sales\"]\n",
        "\n",
        "#grafica de la media movil\n",
        "#moving_avg.plot(label=\"Media Movil\", color=\"red\")\n",
        "#plt.legend(loc=\"best\")\n",
        "\n",
        "\n",
        "\n",
        "#from statsmodels.tsa.stattools import adfuller\n",
        "#def test_stationarity(timeseries):\n",
        "    #determine rolling statistics\n",
        "#    rolmean = pd.Series(timeseries).rolling(window=24).mean()#24 hours on each day\n",
        "#    rolstd = pd.Series(timeseries).rolling(window=24).std()\n",
        "#    #plot rolling statistics\n",
        "#    orig = plt.plot(timeseries,color = 'blue',label='original')\n",
        "#    mean = plt.plot(rolmean,color = 'red',label = 'rolling mean')\n",
        "#    std = plt.plot(rolstd,color = 'black',label = 'rolling std')\n",
        "#    plt.legend(loc = 'best')\n",
        "#    plt.title('rolling mean and standard deviation')\n",
        "#    plt.show(block = False)\n",
        "\n",
        "   #perform dickey fuller test\n",
        "#    print('result of dickey fuller test:')\n",
        "#    dftest = adfuller(timeseries,autolag = 'AIC')\n",
        "#    dfoutput = pd.Series(dftest[0:4],index = ['Test statistics', 'p-value', '#lags used', 'number of observation used'])\n",
        "#    for key,value in dftest[4].items():\n",
        "#        dfoutput['critical value (%s)'%key] = value\n",
        "#    print(dfoutput)\n",
        "\n",
        "#from matplotlib.pylab import rcParams\n",
        "#rcParams['figure.figsize'] = 20,10\n",
        "#test_stationarity(train_original['Count'])\n"
      ],
      "metadata": {
        "id": "wBuhNsLtFon0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df = px.data.gapminder()\n",
        "#Weekly_Sales = df.query(\"Weekly_Sales\")\n",
        "\n",
        "#for template in [\"plotly\", \"plotly_white\", \"plotly_dark\", \"ggplot2\", \"seaborn\", \"simple_white\", \"none\"]:\n",
        "#    fig = px.scatter(Weekly_Sales,\n",
        "#                     x=\"gdpPercap\", y=\"lifeExp\", size=\"pop\", color=\"continent\",\n",
        "#                     log_x=True, size_max=60,\n",
        "#                     template=template, title=\"Gapminder 2007: '%s' theme\" % template)\n",
        "#    fig.show()\n",
        "\n",
        "\n",
        "#df = px.data.gapminder()\n",
        "#df_2007 = df.query(\"year==2007\")\n",
        "\n",
        "#for template in [\"plotly\", \"plotly_white\", \"plotly_dark\", \"ggplot2\", \"seaborn\", \"simple_white\", \"none\"]:\n",
        "#    fig = px.scatter(df_2007,\n",
        "#                     x=\"gdpPercap\", y=\"lifeExp\", size=\"pop\", color=\"continent\",\n",
        "#                     log_x=True, size_max=60,\n",
        "#                     template=template, title=\"Gapminder 2007: '%s' theme\" % template)\n",
        "#    fig.show()"
      ],
      "metadata": {
        "id": "KtLBALLLokiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#f.[\"Temperature\"].plot(figsize=(20,8))\n",
        "\n",
        "#df.plot()"
      ],
      "metadata": {
        "id": "5qyUL3ar4ZUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.plot(test)\n",
        "\n",
        "train = df_clean['Weekly_Sales']\n",
        "test = df_clean['Weekly_Sales']\n",
        "plt.plot(train)\n",
        "plt.plot(test)\n"
      ],
      "metadata": {
        "id": "EqUOiMTxK7lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(50,6))\n",
        "df_clean['Weekly_Sales'].plot()"
      ],
      "metadata": {
        "id": "TU_UlXEOLHNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model_auto_arima = auto_arima(train_data_diff, trace=True,start_p=0, start_q=0, start_P=0, start_Q=0,\n",
        "#                  max_p=20, max_q=20, max_P=20, max_Q=20, seasonal=True,maxiter=200,\n",
        "#                  information_criterion='aic',stepwise=False, suppress_warnings=True, D=1, max_D=10,\n",
        "#                  error_action='ignore',approximation = False)\n",
        "#model_auto_arima.fit(train_data_diff)"
      ],
      "metadata": {
        "id": "ZH0D3EInLTX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_clean[['Store','Fuel_Price','CPI','Unemployment','Day','Month','Year']]\n",
        "y = df_clean['Weekly_Sales']"
      ],
      "metadata": {
        "id": "4lRYk8zcMZU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 100)"
      ],
      "metadata": {
        "id": "FlD_7-kqMfI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "7e92HBrMMjJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.coef_"
      ],
      "metadata": {
        "id": "8Y-2uJZQMtIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.mean()"
      ],
      "metadata": {
        "id": "QjqXIr4JMxGb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyN6+YTrA3JguoTFj3MP3Xqm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}