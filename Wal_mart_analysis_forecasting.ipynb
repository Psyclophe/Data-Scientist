{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Psyclophe/Data-Scientist/blob/main/Wal_mart_analysis_forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odggQqNPY5hY"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "from pandas.core.indexes.datetimes import date\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import statsmodels as sm\n",
        "import sklearn as sl\n",
        "\n",
        "!pip install pmdarima\n",
        "\n",
        "import pmdarima as pm\n",
        "from pmdarima.arima import auto_arima\n",
        "from pmdarima.model_selection import train_test_split\n",
        "from pmdarima.pipeline import Pipeline\n",
        "from pmdarima.preprocessing import BoxCoxEndogTransformer\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import datetime as dt\n",
        "\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "import statsmodels.stats.multicomp as multi\n",
        "\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "import statsmodels.stats.multicomp as mutti\n",
        "\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "from statsmodels.compat.scipy import _next_regular\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings (\"ignore\")\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sección 1.***Obtención de Datos***\n",
        "es este apartado se sube la información del dataFrame en github\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Zt9zsKvTU9qF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKC_NnshZ7_h"
      },
      "outputs": [],
      "source": [
        "#se cargan los datos de entrada proporcionado en el proyecto de las tiendas Wal-mart, asimismo se hace la conexión de los datos a Github mostrado en la siguiente ruta\n",
        "#de la misma forma se indica a Python muestre los primeros \"15\" registros\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/Psyclophe/Data-Scientist/main/Walmart_Store_sales.csv'\n",
        "df = pd.read_csv (url)\n",
        "print('Shape of data',df.shape)\n",
        "df.head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sección 2. **Análisis Exploratorio**\n",
        "en esta sección se procede a realizar el análisis de la información proporcionada con Python"
      ],
      "metadata": {
        "id": "WyNtZnoSUnNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#para identificar el tipo de datos se pide a Python que nos muestre los diferentes tipos datos y, poder detectar la cantidad de datos nulos\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "TzHDPmGT0ort"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2UFhH8vfble"
      },
      "outputs": [],
      "source": [
        "#con la carga de informacion y con esta funcion se pide a Python indicar el tipo de dato de cada columna, para analizar si es necesario hacer cambios en el tipo de \n",
        "#dato en el dataframe y poder tener datos homogeneos se identifico que \"Date\" es un dato que es objeto y se debe convertir a dato fecha\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "QWGquBuQPb4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#en esta funcion se pide a Python convertir los datos objeto a string aquí podemos visualizar que el dato que era un objeto \"Date\" se conviritio al formato fecha \n",
        "#en donde se visualiza \"datetime64[ns]\"\n",
        "df[\"Date\"]=pd.to_datetime(df[\"Date\"])\n",
        "df.info()"
      ],
      "metadata": {
        "id": "f8Arzv6O0ZlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se pide a Pyhon poner en formato a las cifras de la informacion de dataset\n",
        "pd.options.display.float_format='{:,.2f}'.format"
      ],
      "metadata": {
        "id": "96wb7KgnS6Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K98BydgOkKFi"
      },
      "outputs": [],
      "source": [
        "#con esta funcion se da la instrucción a Python para ver las medidas de tendencia central de las 8 columnas\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-50MQCZDaCK8"
      },
      "outputs": [],
      "source": [
        "#se da la instruccion a Python que se ordene las fechas de menor a mayor en el archivo que se va a analizar asimismo se indica al programa que ordene por fechas, \n",
        "#de la mas antigua hasta la mas reciente\n",
        "data_sort=df.sort_values(\"Date\")\n",
        "data_sort"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se pide a Python separar el dato \"Date\" en year, quarter, month, week & day,\n",
        "df[\"Year\"]= df['Date'].dt.year\n",
        "df[\"Quarter\"]= df['Date'].dt.quarter\n",
        "df[\"Month\"]= df['Date'].dt.month\n",
        "df[\"Week\"]= df['Date'].dt.week\n",
        "df[\"Day\"]= df['Date'].dt.day\n",
        "df"
      ],
      "metadata": {
        "id": "GcKqVBpwLILa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVngjONhooXn"
      },
      "outputs": [],
      "source": [
        "#con la funcion \"groupby\" se indica a Python agrupar y sumar, por tienda y por semana, al ejecutar el script Python agrega e indexa la columna \"0\" a la columna \"1\" \n",
        "#como identificador\n",
        "group=df.groupby(\"Store\").sum(\"Weekly_Sales\")\n",
        "group.reset_index(level=0, inplace=True)\n",
        "group[\"Weekly_Sales\"]=(group[\"Weekly_Sales\"])\n",
        "group"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sort_WeeklySales=group.sort_values('Weekly_Sales', ascending=False)\n",
        "sort_WeeklySales"
      ],
      "metadata": {
        "id": "XxvYCQl36hYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Top_five=sort_WeeklySales[['Weekly_Sales', 'Store']][0:5:].reset_index(drop=True)\n",
        "Top_five"
      ],
      "metadata": {
        "id": "3FRkYxUg6T-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se pide a Python agrupar por Year\n",
        "group=df.groupby(\"Year\").sum(\"Weekly_Sales\")\n",
        "group.reset_index(level=0, inplace=True)\n",
        "group[\"Weekly_Sales\"]=(group[\"Weekly_Sales\"])\n",
        "group"
      ],
      "metadata": {
        "id": "Is5jyWjTh06v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se pide a Python agrupar por Quarter\n",
        "group=df.groupby(\"Quarter\").sum(\"Weekly_Sales\")\n",
        "group.reset_index(level=0, inplace=True)\n",
        "group[\"Weekly_Sales\"]=(group[\"Weekly_Sales\"])\n",
        "group"
      ],
      "metadata": {
        "id": "54f2mbgDO-gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se pide a Python ordenar por Store \n",
        "df.set_index('Store')"
      ],
      "metadata": {
        "id": "ZciZl4mAklom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se pide a Python graficar las ventas por año y por mes\n",
        "plt.figure(figsize=(20,8))\n",
        "sns.lineplot(data=df, x='Month', y='Weekly_Sales', hue='Year', palette='tab10')\n",
        "sns.set_style('whitegrid')\n",
        "sns.despine(left=True, offset=20, trim=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ThCT7FayQ177"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import cufflinks as cf\n",
        "#from IPython.display import display, HTML\n",
        "\n",
        "#cf.set_config_file(sharing='public', theme='ggplot', offline=True)\n",
        "#cf.getThemes()"
      ],
      "metadata": {
        "id": "Fg2IEqRwrjAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_pivot = df.pivot(index='Weekly_Sales', columns = 'Month',\n",
        "#              values = 'Store')"
      ],
      "metadata": {
        "id": "w_8qCkSdGqNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_pivot = df_pivot[['Month','Store]]\n",
        "#df_pivot.iplot(kind='line'\n"
      ],
      "metadata": {
        "id": "yCCdEds5FEF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se agrupan las ventas por el segundo y tercer Q de 2012\n",
        "Q2_sales = df[(df['Date'] >= '2012-04-01') & (df['Date'] <= '2012-06-30')].groupby('Store')['Weekly_Sales'].sum()\n",
        "Q3_sales = df[(df['Date'] >= '2012-07-01') & (df['Date'] <= '2012-09-30')].groupby('Store')['Weekly_Sales'].sum()\n",
        "\n",
        "#con este script se grafica la diferencia en ventas por el segundo y tercer Q\n",
        "plt.figure(figsize=(20,8))\n",
        "Q2_sales.plot(ax=Q3_sales.plot(kind ='bar'),kind='bar',color='g',alpha=0.2,legend=True)\n",
        "plt.legend([\"Q3' 2012\", \"Q2' 2012\"])"
      ],
      "metadata": {
        "id": "vmSyMAWzq3P0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#en este script se determina el crecimiento entre los Q2 y Q3\n",
        "Q2_sales= df[(df['Date'] >= '2012-04-01') & (df['Date'] <= '2012-06-30')].groupby('Store')['Weekly_Sales'].sum()\n",
        "Q3_sales= df[(df['Date'] >= '2012-07-01') & (df['Date'] <= '2012-09-30')].groupby('Store')['Weekly_Sales'].sum()\n",
        "quarterly_growth_rate = ((Q3_sales - Q2_sales )/Q2_sales)*100\n",
        "quarterly_growth_rate.sort_values(ascending=False).head()"
      ],
      "metadata": {
        "id": "MwwR3NQVzMpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "quarterly_growth_rate.sort_values(ascending=False).plot(kind='bar')"
      ],
      "metadata": {
        "id": "lJpVE9-zzaaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df=pd('Quarter')\n",
        "#df_Quarter=df[\"Date\"].dt.quarter\n",
        "#Period=df[period.third_quarter('Date')]\n",
        "#df = df.index.quarter\n",
        "#group=df.groupby(df.index.quarter).head(1).reset_index()\n",
        "#group"
      ],
      "metadata": {
        "id": "6-OnSUXzvnH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#se solicita a Python ordenar por tienda y por volumen de ventas, del valor mayor al menor\n",
        "sort_WeeklySales=group.sort_values('Weekly_Sales', ascending=False)\n",
        "sort_WeeklySales"
      ],
      "metadata": {
        "id": "megkRNSqYZaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Total_sales= df.groupby('Store')['Weekly_Sales'].sum().sort_values()\n",
        "Total_sales_array = np.array(Total_sales)\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.xticks(rotation=0)\n",
        "plt.ticklabel_format(useOffset=False, style='plain', axis='y')\n",
        "plt.title('Sales by store')\n",
        "plt.xlabel('Store')\n",
        "plt.ylabel('Total Sales')\n",
        "Total_sales.plot(kind='bar')"
      ],
      "metadata": {
        "id": "JXMNf3-d8hOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script le indicamos a Python que solo nos indique el Top_five de las ventas por tienda\n",
        "\n",
        "#Top_five=sort_WeeklySales[['Weekly_Sales', 'Store']][0:5:].reset_index(drop=True)\n",
        "#Top_five"
      ],
      "metadata": {
        "id": "gtSAJHai0DlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sort_Quarter=Quarter[['Year', 'Quarter']][0:5:].reset_index(drop=True)\n",
        "#Sort_Quarter\n"
      ],
      "metadata": {
        "id": "BAO3LHJvbIqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#es este script se solicita a Python calcular la Desviacion Estandar por tienda, ordenanda de mayor a menor\n",
        "Store_devstd = df.groupby('Store')['Weekly_Sales'].std()\n",
        "Store_devstd = pd.DataFrame(Store_devstd)\n",
        "Store_devstd=Store_devstd.sort_values('Weekly_Sales', ascending=False)\n",
        "Store_devstd"
      ],
      "metadata": {
        "id": "sl0X1ax8GmgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script Python hace el calculo de la tienda con más desviacion estandar\n",
        "top_std = pd.DataFrame(df.groupby('Store')['Weekly_Sales'].std().sort_values(ascending=False))\n",
        "top_std.head(1).index[0] , top_std.head(1).Weekly_Sales[top_std.head(1).index[0]] "
      ],
      "metadata": {
        "id": "d_ttf8iQlVnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "sns.distplot(df[df['Store'] == top_std.head(1).index[0]]['Weekly_Sales'])\n",
        "plt.title('The Sales Distribution of Store No.'+ str(top_std.head(1).index[0]))\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "jTufXf7w92-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# con este script se determina el -Coeficiente de Desviación Medio- por tienda el\n",
        "#se determino dividiendo la DesvStd por tienda entre la media de las tiendas, como sigue coeficiente_DM = Desviación Estandar / media aritmetica * 100\n",
        "coeficiente_DM = pd.DataFrame(df.groupby('Store')['Weekly_Sales'].std() / df.groupby('Store')['Weekly_Sales'].mean()*100)\n",
        "coeficiente_DM.head(5)"
      ],
      "metadata": {
        "id": "NaGBlE2VX3Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#coef = pd.DataFrame(df.groupby('Store')['Weekly_Sales'].std() / df.groupby('Store')['Weekly_Sales'].mean())\n",
        "#coef = pd.DataFrame(df.groupby('Store')['Weekly_Sales'].std() / df.groupby('Store')['Weekly_Sales'].mean()*100)\n",
        "#coef = coef.rename(columns={'Weekly_Sales':'Coeficiente de DesvSTD'})\n",
        "#coef_max = coef.sort_values(by='Coeficiente de DesvStd',ascending=False)\n",
        "#coef_max.head(5)\n",
        "\n",
        "\n",
        "coef = pd.DataFrame(df.groupby('Store')['Weekly_Sales'].std() / df.groupby('Store')['Weekly_Sales'].mean())\n",
        "coef = coef.rename(columns={'Weekly_Sales':'Coefficient of mean to standard deviation'})\n",
        "coef_max = coef.sort_values(by='Coefficient of mean to standard deviation',ascending=False)\n",
        "coef_max.head(7)"
      ],
      "metadata": {
        "id": "M7j5Cq82-cnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se pide a Python graficar la distribucion de las Ventas\n",
        "plt.figure(figsize=(20,8))\n",
        "sns.distplot(df[df['Store'] == coef_max.head(1).index[0]]['Weekly_Sales'])\n",
        "plt.title('Sales distribution of Store No.'+str(coef_max.head(1).index[0]))\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "JBPS24HD_TqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se pide a Python identificar los días festivos\n",
        "df_Holiday=df[df[\"Holiday_Flag\"]==1]\n",
        "df_Holiday"
      ],
      "metadata": {
        "id": "RQ-27JzWEdaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con esta instruccion se definen los Días festivos que encontro Pyton en el dataframe\n",
        "Super_Bowl =['2010-12-02', '2011-11-02', '2012-10-02']\n",
        "Labor_Day =  ['2010-10-09', '2011-09-09', '2012-07-09']\n",
        "Thanksgivig_Day =  ['2010-11-26', '2011-11-25', '2012-11-23']\n",
        "Xmas = ['2010-12-31', '2011-12-30', '2012-12-28']"
      ],
      "metadata": {
        "id": "mSNpf7TyIZVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se pide a Python sumar los dias festivos\n",
        "add_days = Super_Bowl + Labor_Day + Thanksgivig_Day + Xmas\n",
        "add_days\n",
        "df[\"Holiday_Flag\"] = np.where(df[\"Holiday_Flag\"] == 1, df[\"Holiday_Flag\"], df[\"Holiday_Flag\"].isin(add_days))\n",
        "df['Holiday_Flag'].value_counts()"
      ],
      "metadata": {
        "id": "lo-psDwjahEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.loc[df.Date.isin(Super_Bowl)].Date.unique()"
      ],
      "metadata": {
        "id": "w2d6RqtvEGKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.loc[df.Date.isin(Labor_Day)].Date.unique()"
      ],
      "metadata": {
        "id": "Tch_nwCbIIm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.loc[df.Date.isin(Thanksgivig_Day)].Date.unique()"
      ],
      "metadata": {
        "id": "B4s1tsdiIB7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.loc[df.Date.isin(Xmas)].Date.unique()"
      ],
      "metadata": {
        "id": "QAS3tLsMIQjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con esta instruccion se pide a Python determinar la media de ventas de los Dias_Festivos\n",
        "Sales_Super_Bowl= (pd.DataFrame(df.loc[df.Date.isin(Super_Bowl)]))['Weekly_Sales'].mean()\n",
        "Sales_Labor_Day = (pd.DataFrame(df.loc[df.Date.isin(Labor_Day)]))['Weekly_Sales'].mean()\n",
        "Sales_Thanksgivig_Day = (pd.DataFrame(df.loc[df.Date.isin(Thanksgivig_Day)]))['Weekly_Sales'].mean()\n",
        "Sales_Xmas = (pd.DataFrame(df.loc[df.Date.isin(Xmas)]))['Weekly_Sales'].mean()\n",
        "{Sales_Super_Bowl, Sales_Labor_Day, Sales_Thanksgivig_Day, Sales_Xmas}"
      ],
      "metadata": {
        "id": "GtIItzEHN_oH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con esta instruccion se pide a Python determinar la media de ventas de los Dias_No_Festivos\n",
        "Sales_not_Holiday = df[df['Holiday_Flag'] == 0 ]['Weekly_Sales'].mean()\n",
        "{Sales_not_Holiday}"
      ],
      "metadata": {
        "id": "rUSlykMtSRAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con esta instruccion se pide a Python determinar el promedio de ventas \n",
        "Average_sales = {'Sales_Super_Bowl' : Sales_Super_Bowl,\n",
        "                 'Sales_Labor_Day': Sales_Labor_Day,\n",
        "                 'Sales_Thanksgiving_Day':Sales_Thanksgivig_Day,\n",
        "                 'Sales_Xmas': Sales_Xmas,\n",
        "                 'Sales_not_Holiday': Sales_not_Holiday}\n",
        "Average_sales "
      ],
      "metadata": {
        "id": "oVXZJfSBI4ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Sales_Quarter=df.groupby('Quarter')['Weekly_Sales'].sum()\n",
        "Sales_Quarter"
      ],
      "metadata": {
        "id": "cOU4f_HuvLcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('Quarter').sum()"
      ],
      "metadata": {
        "id": "sVs9AMBZxTu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "plt.bar(df[\"Month\"],df[\"Weekly_Sales\"])\n",
        "plt.xlabel(\"Months\")\n",
        "plt.ylabel(\"Weekly Sales\")\n",
        "plt.title(\"Top_five\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ulRVIqvJBEHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Yearly Sales\n",
        "plt.figure(figsize=(20,8))\n",
        "df.groupby(\"Year\")[[\"Weekly_Sales\"]].sum().plot(kind='bar',legend=False)\n",
        "plt.xlabel(\"Years\")\n",
        "plt.ylabel(\"Weekly Sales\")\n",
        "plt.title(\"Yearly view of sales\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ehjJbp7n0y98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "sns.lineplot(data=df, x='Quarter', y='Weekly_Sales', hue='Year', palette='tab10')\n",
        "sns.set_style('whitegrid')\n",
        "sns.despine(left=True, offset=20, trim=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Emr0ZIOoFVpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.groupby.groupby import DataFrame\n",
        "\n",
        "#con este script se pide a Python realizar la suma y acumulacion por Quarter\n",
        "pd=DataFrame({'Year', 'Quarter'})\n",
        "print(df.groupby(['Year', 'Quarter']).sum().groupby(level=[0]).cumsum())"
      ],
      "metadata": {
        "id": "UHLAUV5vx7z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se pide a Python sumar el total de ventas por Quarter\n",
        "Sales_Year=df.groupby('Year')['Weekly_Sales'].sum()\n",
        "Sales_Year"
      ],
      "metadata": {
        "id": "165wxfb9vVZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(20,8))\n",
        "sns.lineplot(data=df, x='Year', y='Weekly_Sales', hue='Quarter', palette='tab10')\n",
        "sns.set_style('whitegrid')\n",
        "sns.despine(left=True, offset=20, trim=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K-5h_CYFxoer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df = df.set_index['Date']\n",
        "#group=df.groupby(df.index.quarter).head(1).reset_index()\n",
        "#print('Shape of data',df.shape)\n",
        "#group"
      ],
      "metadata": {
        "id": "lanXcHPawaER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se muestra en crecimiento tercer trimestre 2012 por tienda\n",
        "\n",
        "#third_quarter= df[(df['Date'] >= '2012-07-01') & (df['Date'] <= '2012-09-30')].groupby('Store')['Weekly_Sales'].sum().sort_values()\n",
        "#plt.figure(figsize=(15,7))\n",
        "#third_quarter.plot(kind='bar',legend=True)\n",
        "#plt.ticklabel_format( style='plain', axis='y')\n",
        "#plt.legend([\"3-Quarter' 2012\"]);\n"
      ],
      "metadata": {
        "id": "jAfPHkBkcE6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se pide a Python graficar las Ventas mensuales por cada año \n",
        "plt.figure(figsize=(20,8))\n",
        "plt.scatter(df[df.Year==2010][\"Month\"],df[df.Year==2010][\"Weekly_Sales\"])\n",
        "plt.xlabel(\"Months\")\n",
        "plt.ylabel(\"Weekly Sales\")\n",
        "plt.title(\"Monthly view of sales in 2010\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.scatter(df[df.Year==2011][\"Month\"],df[df.Year==2011][\"Weekly_Sales\"])\n",
        "plt.xlabel(\"Months\")\n",
        "plt.ylabel(\"Weekly Sales\")\n",
        "plt.title(\"Monthly view of sales in 2011\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.scatter(df[df.Year==2012][\"Month\"],df[df.Year==2012][\"Weekly_Sales\"])\n",
        "plt.xlabel(\"Months\")\n",
        "plt.ylabel(\"Weekly Sales\")\n",
        "plt.title(\"Monthly view of sales in 2012\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MFNT-chLshTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con esta instrucción se pide a Python graficar las ventas de los tres años de manera mensual\n",
        "plt.figure(figsize=(20,8))\n",
        "sns.lineplot(data=df, x='Month', y='Weekly_Sales', hue='Year', palette='tab10')\n",
        "sns.set_style('whitegrid')\n",
        "sns.despine(left=True, offset=20, trim=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C0_RiJNuwief"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Series de tiempo**"
      ],
      "metadata": {
        "id": "xtdk68Gj6wOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 8))\n",
        "plt.plot(df.index, df['Weekly_Sales'])\n",
        "\n",
        "plt.xlabel('Year', fontsize=14 )\n",
        "plt.ylabel('Quarter', fontsize=14)\n",
        "plt.title('Series de tiempo', fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zboZQcYcG4RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "x=['Holiday_Flag']\n",
        "y=['Weekly_Sales']\n",
        "stats.kruskal(x,y)"
      ],
      "metadata": {
        "id": "QIs0f3ZxP0W0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=df[df['Holiday_Flag'] == 0]['Weekly_Sales']\n",
        "y=df[df['Holiday_Flag'] == 1]['Weekly_Sales']\n",
        "stats.kruskal(x,y)"
      ],
      "metadata": {
        "id": "CYTU3exWP8mE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sección 3. **Quitar Valores de Rango**\n",
        "en esta sección del codigo se analiza la información para quitar los valores fuera de rango\n"
      ],
      "metadata": {
        "id": "jqh0mU0kv5fN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se grafican y validan los valores atipicos\n",
        "fig, axis = plt.subplots(4,figsize=(16,16))\n",
        "X = df[['Temperature','Fuel_Price','CPI','Unemployment']]\n",
        "for i,column in enumerate(X):\n",
        "    sns.boxplot(df[column],ax=axis[i])\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "rTyptJonwBIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walmart_data_clean = df[(df['Unemployment']<10) & (df['Unemployment']>4.5) & (df['Temperature']>10)]\n",
        "walmart_data_clean"
      ],
      "metadata": {
        "id": "M4FdGL0X1fbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(data=df,x='Temperature', y='Weekly_Sales', hue='Year', style='Year')\n",
        "#sns.scatterplot(data=df,x='Temperature', y='Weekly_Sales', hue='Year')\n",
        "plt.axvline(x=10,color='b')"
      ],
      "metadata": {
        "id": "5zX7lA0HZmg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sns.scatterplot(data=df,x='Holiday_Flag', y='Temperature')\n"
      ],
      "metadata": {
        "id": "o7u6GhF9U5mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(data=df,x='Unemployment', y='Weekly_Sales', hue='Year', style='Year')\n",
        "plt.axvline(x=4.5,color='b')"
      ],
      "metadata": {
        "id": "1xtzeTPUwJYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script pedimos aPython eliminar los valores atipicos en una nueva función\n",
        "df_clean = df[(df['Unemployment']<10) & (df['Unemployment']>4.5) & (df['Temperature']>10)]\n"
      ],
      "metadata": {
        "id": "UDqDTjjgaq-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walmart_data_clean = df[(df['Unemployment']<10) & (df['Unemployment']>4.5) & (df['Temperature']>10)]\n",
        "walmart_data_clean"
      ],
      "metadata": {
        "id": "SuWrdbTY1h6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lim_inf = Q1 - 1.5(whis) IQR (scipy.stats.iqr)\n",
        "#iqr = Q3 - Q1\n",
        "#lim_sup = Q3 + 1.5(whis) IQR"
      ],
      "metadata": {
        "id": "evCLp-chd6C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking data for outliers\n",
        "fig, axis = plt.subplots(4,figsize=(16,16))\n",
        "X = df_clean[['Temperature','Fuel_Price','CPI','Unemployment']]\n",
        "for i,column in enumerate(X):\n",
        "    sns.boxplot(df_clean[column], ax=axis[i])\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "qboDloxI14Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificamos ya no tener valores atipicos\n",
        "fig, axis = plt.subplots(4,figsize=(16,16))\n",
        "X = df_clean[['Temperature','Fuel_Price','CPI','Unemployment']]\n",
        "for i,column in enumerate(X):\n",
        "    sns.boxplot(df_clean[column],ax=axis[i])\n"
      ],
      "metadata": {
        "id": "3_IZNvZCaw7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este grafico de calor podemos ver las correlaciones de las diferentes columnas\n",
        "plt.figure(figsize = (12,10))\n",
        "sns.heatmap(df_clean.corr().abs())    \n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YDRVQJsja9tD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sección 4. **Modelos y Pronostico**\n",
        "\n",
        "en esta sección del codigo se procede a realizar el modelado de la información"
      ],
      "metadata": {
        "id": "mFf_DFQk6P11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression :\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LinearRegression\n",
        "X = walmart_data_clean[['Store','Fuel_Price','CPI','Unemployment','Day','Month','Year']]\n",
        "Y = walmart_data_clean['Weekly_Sales']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2)"
      ],
      "metadata": {
        "id": "gbk0W1A-2btd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Linear Regression:')\n",
        "print()\n",
        "reg = LinearRegression()\n",
        "reg.fit(X_train, Y_train)\n",
        "Y_pred = reg.predict(X_test)\n",
        "print('Accuracy:',reg.score(X_train, Y_train)*100)\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, Y_pred))\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(Y_test, Y_pred))\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, Y_pred)))\n",
        "sns.scatterplot(Y_pred, Y_test)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "-Lj96vc42g0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Regressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "print('Random Forest Regressor:')\n",
        "print()\n",
        "rfr = RandomForestRegressor()        \n",
        "rfr.fit(X_train,Y_train)\n",
        "Y_pred = rfr.predict(X_test)\n",
        "print('Accuracy:',rfr.score(X_test, Y_test)*100)\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, Y_pred))\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(Y_test, Y_pred))\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, Y_pred)))\n",
        "sns.scatterplot(Y_pred, Y_test)\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "zfZsyWLF2poj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sns.distplot=sns.distplot('Quarter')"
      ],
      "metadata": {
        "id": "59FxkQr9jf4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import prophet as ppt"
      ],
      "metadata": {
        "id": "kRHj3JGBJ9H2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este script se solicita a Python calcular el analsis de variaza entre 'Holiday_ Flag' vs 'Weekly_Sales', el modelo indica que la variacion\n",
        "#es pequeña indicando al modelo que los Holiday no afecta las ventas semanales de manera significativa\n",
        "\n",
        "model = smf.ols ('Holiday_Flag ~ Weekly_Sales', data = df).fit()\n",
        "aov_table = anova_lm(model, type=2)\n",
        "\n",
        "#anova_result = sm.stats.anova_lm(model, type=2)\n",
        "print(aov_table)"
      ],
      "metadata": {
        "id": "S5P_FibdKjcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "from pmdarima import auto_arima"
      ],
      "metadata": {
        "id": "gSJrsEa5agFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_arima=df\n",
        "#df_arima=df_arima.set_index('Date').reset.index()"
      ],
      "metadata": {
        "id": "i0M9_sIl6HOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.figure(figsize=(20,9))\n",
        "#df_arima['Weekly_Sales'].plot()\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "2U-xeXV_6mEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_arimamonth = df_arima.resample('M').mean()"
      ],
      "metadata": {
        "id": "igL9dh2p7AAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.figure(figsize=(20,8))\n",
        "#df_arimamonth['Weekly_Sales'].plot()\n",
        "#plt.title('Average Sales - Weekly')\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "KBvKckbH7PJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_data = df_arimamonth[:int(0.7*(len(df_arimamonth)))] \n",
        "#test_data = df_arimamonth[int(0.7*(len(df_arimamonth))):]\n",
        "\n",
        "#print('Train:', train_data.shape)\n",
        "#print('Test:', test_data.shape)"
      ],
      "metadata": {
        "id": "k8HY0hu97gAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_data['Weekly_Sales'].plot(figsize=(20,8), title= 'Weekly_Sales', fontsize=14)\n",
        "#test_data['Weekly_Sales'].plot(figsize=(20,8), title= 'Weekly_Sales', fontsize=14)\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "iOhwuHro7kby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from pmdarima.arima import ADFTest\n",
        "#adf_test = ADFTest(alpha = 0.05)\n",
        "#adf_test.should_diff (df_arimamonth['Weekly_Sales'])"
      ],
      "metadata": {
        "id": "TINXW7s672qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model_auto_arima = auto_arima(train_data['Weekly_Sales'], trace=True,start_p=0, start_q=0, start_P=0, start_Q=0,\n",
        "#                  max_p=20, max_q=20, max_P=20, max_Q=20, seasonal=True,maxiter=200,\n",
        "#                  information_criterion='aic',stepwise=False, suppress_warnings=True, D=0, max_D=0,\n",
        "#                  error_action='ignore',approximation = False)\n",
        "#model_auto_arima.fit(train_data['Weekly_Sales'])"
      ],
      "metadata": {
        "id": "jMkQg0xq8K35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model_auto_arima.summary()"
      ],
      "metadata": {
        "id": "2Ei9O6rN8TZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y_pred = model_auto_arima.predict(n_periods=len(test_data['Weekly_Sales']))\n",
        "#y_pred = pd.DataFrame(y_pred,index = test_data['Weekly_Sales'].index,columns=['Prediction'])\n",
        "#plt.figure(figsize=(20,6))\n",
        "#plt.title('Prediction of Weekly Sales Using Auto-ARIMA', fontsize=20)\n",
        "#plt.plot(train_data['Weekly_Sales'], label='Train')\n",
        "#plt.plot(test_data['Weekly_Sales'], label='Test')\n",
        "#plt.plot(y_pred, label='Prediction of ARIMA')\n",
        "#plt.legend(loc='best')\n",
        "#plt.xlabel('Date', fontsize=14)\n",
        "#plt.ylabel('Weekly Sales', fontsize=14)\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "RIv8J8NH8Yda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#con este escript se elige el tipo de modelo\n",
        "\n",
        "#import statsmodels as sm\n",
        "#from statsmodels.tsa.arima_model import ARIMA\n",
        "#from statsmodels.tsa.stattools import adfuller\n",
        "#def test_stationarity(timeseries):\n",
        "\n",
        "#estadisticas en la determinación de la media móvil y la desviación estandar\n",
        "#  rolmean = pd.rolling_mean(timeseries, window=12)\n",
        "#  rolstd = pd.rolling_std(timeseries, window=12)\n",
        "\n",
        "#graficar las estadisticas\n",
        "#  orig = plt.plot(timeseries, color=\"blue\", label=\"Original\")\n",
        "#  mean = plt.plot(rolmean, color=\"red\", label=\"Media Movil\")\n",
        "#  std = plt.plot(rolstd, color=\"black\", label=\"Desviacon Estandar\")\n",
        "#  plt.legend(loc=\"best\")\n",
        "#  plt.title(\"Media Movil y Desviacion Estandar\")\n",
        "#  plt.show(block=False)\n",
        "\n",
        "#calculo de la media movil\n",
        "#moving_avg = pd.rolling_mean(datos[\"Weekly_Sales\"], 12)\n",
        "#datos[\"Weekly_Sales\"]\n",
        "\n",
        "#grafica de la media movil\n",
        "#moving_avg.plot(label=\"Media Movil\", color=\"red\")\n",
        "#plt.legend(loc=\"best\")\n",
        "\n",
        "#from statsmodels.tsa.stattools import adfuller\n",
        "#def test_stationarity(timeseries):\n",
        "    #determine rolling statistics\n",
        "#    rolmean = pd.Series(timeseries).rolling(window=24).mean()#24 hours on each day\n",
        "#    rolstd = pd.Series(timeseries).rolling(window=24).std()\n",
        "#    #plot rolling statistics\n",
        "#    orig = plt.plot(timeseries,color = 'blue',label='original')\n",
        "#    mean = plt.plot(rolmean,color = 'red',label = 'rolling mean')\n",
        "#    std = plt.plot(rolstd,color = 'black',label = 'rolling std')\n",
        "#    plt.legend(loc = 'best')\n",
        "#    plt.title('rolling mean and standard deviation')\n",
        "#    plt.show(block = False)\n",
        "\n",
        "   #perform dickey fuller test\n",
        "#    print('result of dickey fuller test:')\n",
        "#    dftest = adfuller(timeseries,autolag = 'AIC')\n",
        "#    dfoutput = pd.Series(dftest[0:4],index = ['Test statistics', 'p-value', '#lags used', 'number of observation used'])\n",
        "#    for key,value in dftest[4].items():\n",
        "#        dfoutput['critical value (%s)'%key] = value\n",
        "#    print(dfoutput)\n",
        "\n",
        "#from matplotlib.pylab import rcParams\n",
        "#rcParams['figure.figsize'] = 20,10\n",
        "#test_stationarity(train_original['Count'])\n"
      ],
      "metadata": {
        "id": "wBuhNsLtFon0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df = px.data.gapminder()\n",
        "#Weekly_Sales = df.query(\"Weekly_Sales\")\n",
        "\n",
        "#for template in [\"plotly\", \"plotly_white\", \"plotly_dark\", \"ggplot2\", \"seaborn\", \"simple_white\", \"none\"]:\n",
        "#    fig = px.scatter(Weekly_Sales,\n",
        "#                     x=\"gdpPercap\", y=\"lifeExp\", size=\"pop\", color=\"continent\",\n",
        "#                     log_x=True, size_max=60,\n",
        "#                     template=template, title=\"Gapminder 2007: '%s' theme\" % template)\n",
        "#    fig.show()\n",
        "\n",
        "#df = px.data.gapminder()\n",
        "#df_2007 = df.query(\"year==2007\")\n",
        "\n",
        "#for template in [\"plotly\", \"plotly_white\", \"plotly_dark\", \"ggplot2\", \"seaborn\", \"simple_white\", \"none\"]:\n",
        "#    fig = px.scatter(df_2007,\n",
        "#                     x=\"gdpPercap\", y=\"lifeExp\", size=\"pop\", color=\"continent\",\n",
        "#                     log_x=True, size_max=60,\n",
        "#                     template=template, title=\"Gapminder 2007: '%s' theme\" % template)\n",
        "#    fig.show()"
      ],
      "metadata": {
        "id": "KtLBALLLokiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#f.[\"Temperature\"].plot(figsize=(20,8))\n",
        "\n",
        "#df.plot()"
      ],
      "metadata": {
        "id": "5qyUL3ar4ZUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.plot(test)\n",
        "\n",
        "#train = df_clean['Weekly_Sales']\n",
        "#test = df_clean['Weekly_Sales']\n",
        "#plt.plot(train)\n",
        "#plt.plot(test)"
      ],
      "metadata": {
        "id": "EqUOiMTxK7lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.figure(figsize=(50,6))\n",
        "#df_clean['Weekly_Sales'].plot()"
      ],
      "metadata": {
        "id": "TU_UlXEOLHNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model_auto_arima = auto_arima(train_data_diff, trace=True,start_p=0, start_q=0, start_P=0, start_Q=0,\n",
        "#                  max_p=20, max_q=20, max_P=20, max_Q=20, seasonal=True,maxiter=200,\n",
        "#                  information_criterion='aic',stepwise=False, suppress_warnings=True, D=1, max_D=10,\n",
        "#                  error_action='ignore',approximation = False)\n",
        "#model_auto_arima.fit(train_data_diff)"
      ],
      "metadata": {
        "id": "ZH0D3EInLTX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X = df_clean[['Store','Fuel_Price','CPI','Unemployment','Day','Month','Year']]\n",
        "#y = df_clean['Weekly_Sales']"
      ],
      "metadata": {
        "id": "4lRYk8zcMZU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.model_selection import train_test_split\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 100)"
      ],
      "metadata": {
        "id": "FlD_7-kqMfI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#model = LinearRegression()\n",
        "#model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "7e92HBrMMjJi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyNKD6/VfyaMSzkboVE4a4Ph",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}